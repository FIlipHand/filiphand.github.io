---
title: GPU programming learning resources
date: '2025-10-02'
tags: ['cuda', 'gpu', 'learning', 'triton', 'mojo']
draft: true
summary: Place to store resources that I used, use or will use on my journey to learn GPU programming (and bunch of other stuff LLM related).
---

#### Books:
- "Programming Massively Parallel Processors: A Hands-on Approach" by Wen-mei W. Hwu, David B. Kirk, Izzat El Hajj

#### YouTube Channels:
- [GPU MODE](https://www.youtube.com/@GPUMODE)
- [0mean1sigma](https://www.youtube.com/@0mean1sigma)
- [Simon Oz](https://www.youtube.com/@szymonozog7862)

#### YouTube videos:
- [CUDA Programming Course - High-Performance Computing with GPUs](https://www.youtube.com/watch?v=86FAWCzIe_4)

#### Blog posts:
- [GPU Glossary by Modal](https://modal.com/gpu-glossary)
- [Roadmap: Understanding GPU Architecture by Cornell University](https://cvw.cac.cornell.edu/gpu-architecture)
- ["Accelerating Generative AI with PyTorch: Segment Anything, Fast" by PyTorch](https://pytorch.org/blog/accelerating-generative-ai/)
- ["Tiny-TPU"](https://www.tinytpu.com/)
- [Fast LLM Inference From Scratch](https://andrewkchan.dev/posts/yalm.html)
- [The Ultra-Scale Playbook: Training LLMs on GPU Clusters](https://huggingface.co/spaces/nanotron/ultrascale-playbook?section=high-level_overview)
- [How to Think About GPUs](https://jax-ml.github.io/scaling-book/gpus)
- [LLM Inference Economics from First Principles](https://www.tensoreconomics.com/p/llm-inference-economics-from-first)
- [Inside vLLM: Anatomy of a High-Throughput LLM Inference System](https://www.aleksagordic.com/blog/vllm)

#### Exercises:
- [MojoðŸ”¥ Puzzles](https://puzzles.modular.com/introduction.html)
- [Triton Puzzles](https://github.com/srush/Triton-Puzzles)

#### Twitter (formerly known as $\mathbb{X}$ ):
- [Elliot Arledge](https://x.com/elliotarledge)
- [maharshi](https://x.com/mrsiipa)
